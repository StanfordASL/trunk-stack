{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "num_seeds = 8\n",
    "data_dir = os.getenv('TRUNK_DATA', '/home/trunk/Documents/trunk-stack/stack/main/data')\n",
    "\n",
    "us_df = pd.read_csv(os.path.join(data_dir, 'trajectories/steady_state/control_inputs_beta_seed0.csv'))\n",
    "for seed in range(1, num_seeds + 1):\n",
    "    us_df = pd.concat([us_df, pd.read_csv(os.path.join(data_dir, f'trajectories/steady_state/control_inputs_beta_seed{seed}.csv'))])\n",
    "us_df = us_df.drop(columns=['ID'])\n",
    "\n",
    "# Observations\n",
    "ys_df = pd.read_csv(os.path.join(data_dir, 'trajectories/steady_state/observations_steady_state_beta_seed0.csv'))\n",
    "for seed in range(1, num_seeds + 1):\n",
    "    ys_df = pd.concat([ys_df, pd.read_csv(os.path.join(data_dir, f'trajectories/steady_state/observations_steady_state_beta_seed{seed}.csv'))])\n",
    "ys_df = ys_df.drop(columns=['ID'])\n",
    "\n",
    "rest_positions = np.array([0.1005, -0.10698, 0.10445, -0.10302, -0.20407, 0.10933, 0.10581, -0.32308, 0.10566])\n",
    "ys_df = ys_df - rest_positions\n",
    "N = len(ys_df)\n",
    "if len(us_df) != N:\n",
    "    us_df = us_df[:N]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "us = us_df.to_numpy()\n",
    "ys = ys_df.to_numpy()\n",
    "\n",
    "G = np.linalg.lstsq(ys, us, rcond=None)[0].T\n",
    "np.save(os.path.join(data_dir, 'models/ik/y2u_8seeds.npy'), G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_inputs: int = 9,\n",
    "                 num_outputs: int = 6,\n",
    "                 num_neurons: list = [32, 32],\n",
    "                 act: nn.Module = nn.Tanh(),  # should be relu for spectral norm to make sense\n",
    "                 spectral_normalize: bool = False):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        if spectral_normalize:\n",
    "            input_layer = spectral_norm(nn.Linear(num_inputs, num_neurons[0]))\n",
    "        else:\n",
    "            input_layer = nn.Linear(num_inputs, num_neurons[0])\n",
    "        layers.append(input_layer)\n",
    "        layers.append(act)\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(len(num_neurons) - 1):\n",
    "            if spectral_normalize:\n",
    "                hidden_layer = spectral_norm(nn.Linear(num_neurons[i], num_neurons[i + 1]))\n",
    "            else:\n",
    "                hidden_layer = nn.Linear(num_neurons[i], num_neurons[i + 1])\n",
    "            layers.append(hidden_layer)\n",
    "            layers.append(act)\n",
    "        \n",
    "        # Output layer\n",
    "        if spectral_normalize:\n",
    "            output_layer = spectral_norm(nn.Linear(num_neurons[-1], num_outputs))\n",
    "        else:\n",
    "            output_layer = nn.Linear(num_neurons[-1], num_outputs)\n",
    "        \n",
    "        layers.append(output_layer)\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        u = x\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('TRUNK_DATA', '/home/trunk/Documents/trunk-stack/stack/main/data')\n",
    "\n",
    "neural_ik_model = MLP()\n",
    "neural_ik_model.load_state_dict(torch.load(os.path.join(data_dir, 'models/ik/neural_ik_model_state.pth'), weights_only=False))\n",
    "neural_ik_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7440327   0.3288924  -0.20543166 -1.6499428  -2.9646416   1.1011922 ]\n"
     ]
    }
   ],
   "source": [
    "zf_sample = [0.0003403276205062866, -0.10695958137512207,-0.0010286569595336914, 0.0024021118879318237, -0.20283722877502441,-0.019539475440979004, -0.007723316550254822, -0.2861044406890869, -0.10018789768218994]\n",
    "avp_offset = torch.tensor([0, -0.10698, 0, 0, -0.20407, 0, 0, -0.32308, 0], dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    nn_output = neural_ik_model(torch.tensor(zf_sample, dtype=torch.float)-avp_offset)\n",
    "u_opt = nn_output.numpy()\n",
    "print(u_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.4033e-04,  2.0422e-05, -1.0287e-03,  2.4021e-03,  1.2328e-03,\n",
       "        -1.9539e-02, -7.7233e-03,  3.6976e-02, -1.0019e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(zf_sample, dtype=torch.float)-avp_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1, u2, u3, u4, u5, u6 = u_opt[0], u_opt[1], u_opt[2], u_opt[3], u_opt[4], u_opt[5]\n",
    "\n",
    "u1_vec = u1 * np.array([-np.cos(15 * np.pi/180), np.sin(15 * np.pi/180)])\n",
    "u2_vec = u2 * np.array([np.cos(45 * np.pi/180), np.sin(45 * np.pi/180)])\n",
    "u3_vec = u3 * np.array([-np.cos(15 * np.pi/180), -np.sin(15 * np.pi/180)])\n",
    "u4_vec = u4 * np.array([-np.cos(75 * np.pi/180), np.sin(75 * np.pi/180)])\n",
    "u5_vec = u5 * np.array([np.cos(45 * np.pi/180), -np.sin(45 * np.pi/180)])\n",
    "u6_vec = u6 * np.array([-np.cos(75 * np.pi/180), -np.sin(75 * np.pi/180)])\n",
    "\n",
    "\n",
    "vector_sum = (\n",
    "    0.75 * (u3_vec + u4_vec) +\n",
    "    1.0 * (u2_vec + u5_vec) +\n",
    "    1.4 * (u1_vec + u6_vec)\n",
    ")\n",
    "norm_value = np.linalg.norm(vector_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1031566923545795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
